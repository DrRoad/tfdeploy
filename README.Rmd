---
title: "tfserve: Tensorflow Serve Examples"
output:
  github_document:
    fig_width: 9
    fig_height: 5
---

This repo provides tools and examples to serve Tensorflow models from R.

## Tensorflow Serving

### Saving a Model

One can train MNIST as described by [MNIST For ML Beginners](https://tensorflow.rstudio.com/tensorflow/articles/tutorial_mnist_beginners.html) and track
the model's inputs and outputs named `x` and `y` under that particular article. For convinience, we can
run instead:

```{r}
library(tensorflow)
library(tfserve)

sess <- tf$Session()
mnist_model <- tfserve_mnist_train(sess)
```

Once trained, the model can be saved with [SavedModelBuilder](https://www.tensorflow.org/api_docs/python/tf/saved_model/builder/SavedModelBuilder).

```{r}
model_path <- file.path("tf/1")
if (dir.exists(model_path)) unlink(model_path, recursive = TRUE)

builder <- tf$saved_model$builder$SavedModelBuilder(model_path)
builder$save()

dir(model_path, recursive = TRUE)
```

However, saving the model is not sufficient when using Tensorflow Serving, see [Serving a Tensorflow Model](https://www.tensorflow.org/serving/serving_basic).

Instead, we need to create a signature for the model, which will require references to the
input and output Tensors for the model which we retrieved from the model:

```{r}
mnist_model
```

with them, we can use the following convenience function to retrieve the signature for the model:

```{r}
signature <- tfserve_mnist_signature(mnist_model$input, mnist_model$output)
```

This signature can be used in combination with `SavedModelBuilder.add_meta_graph_and_variables` to
provide a model usable with Tensorflow Serving:

```{r}
tfserve_save(sess, model_path, signature, overwrite = TRUE)

dir(model_path, recursive = TRUE)
```

### Serving a Model

See [Tensorflow Serving Setup](https://www.tensorflow.org/serving/setup#installing_using_apt-get), but in general, from Linux, first install prereqs:

```{bash eval=F}
sudo apt-get update && sudo apt-get install -y build-essential curl libcurl3-dev git libfreetype6-dev libpng12-dev libzmq3-dev pkg-config python-dev python-numpy python-pip software-properties-common swig zip zlib1g-dev
```

Then install Tensorflow Serving:

```{bash eval=F}
echo "deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list

curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -

sudo apt-get update && sudo apt-get install tensorflow-model-server
```

Optionally, install the api client:

```{bash eval=F}
sudo pip install tensorflow-serving-api --no-cache-dir
```

Then serve the model using:

```{bash eval=F}
tensorflow_model_server --port=9000 --model_name=mnist --model_base_path=/mnt/hgfs/tfserve/tf/
```
