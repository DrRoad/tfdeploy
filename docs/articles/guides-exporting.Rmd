---
title: "Exporting Models"
---

```{r setup, include=FALSE}
library(tensorflow)
knitr::opts_chunk$set(eval = TRUE)
```

## Overview

The first step towards deploying a trained model is to export this model from
TensorFlow. This guide demostrates how to export models from: TensorFlow,
tfestimators and keras.

## Exporting from TensorFlow

One can train MNIST as described by [MNIST For ML Beginners](https://tensorflow.rstudio.com/tensorflow/articles/tutorial_mnist_beginners.html) and track
the model's inputs and outputs named `x` and `y` under that particular article. For convinience, we can
run instead:

```{r}
Sys.setenv(RETICULATE_TRACE = 1000)

library(tensorflow)
library(tfserve)

sess <- tf$Session()
mnist_model <- mnist_train(sess)
```

Once trained, the model can be saved with [SavedModelBuilder](https://www.tensorflow.org/api_docs/python/tf/saved_model/builder/SavedModelBuilder).

```{r}
if (dir.exists("trained")) unlink("trained", recursive = TRUE)

model_path <- file.path("trained/tensorflow-mnist/1")

builder <- tf$saved_model$builder$SavedModelBuilder(model_path)
builder$save()

dir(model_path, recursive = TRUE)
```

However, saving the model is not sufficient when using Tensorflow Serving, see [Serving a Tensorflow Model](https://www.tensorflow.org/serving/serving_basic).

Instead, we need to create a signature for the model, which will require references to the
input and output Tensors for the model which we retrieved from the model:

```{r}
mnist_model
```

with them, we can use the following convenience function to retrieve the signature for the model:

```{r}
signature <- mnist_signature(mnist_model$input, mnist_model$output)
```

This signature can be used in combination with `SavedModelBuilder.add_meta_graph_and_variables` to
provide a model usable with Tensorflow Serving:

```{r}

tfserve_save <- function(sess, model_path, signature, overwrite = FALSE) {
  if (overwrite && dir.exists(model_path)) unlink(model_path, recursive = TRUE)
  builder <- tf$saved_model$builder$SavedModelBuilder(model_path)

  if (!is.null(signature)) {
    legacy_init_op <- tf$group(tf$tables_initializer(), name = "legacy_init_op")

    builder$add_meta_graph_and_variables(
      sess,
      list(
        tf$python$saved_model$tag_constants$SERVING
      ),
      signature_def_map = signature,
      legacy_init_op = legacy_init_op
    )
  }

  builder$save()
}

tfserve_save(sess, model_path, signature, overwrite = TRUE)

dir(model_path, recursive = TRUE)
```

## Exporting from TFEstimators

A sample model using the `mtcars` data frame is trained using `tfestimators`.  The resulting model is the one that will be saved to disk. To train, we can follow the TensorFlow estimators [Quick Start](https://tensorflow.rstudio.com/tfestimators/); or for convenienve, run:

```{r}
library(tfestimators)

mtcars_train <- function () {
  mtcars_input_fn <- function(data) {
    input_fn(data,
             features = c("disp", "cyl"),
             response = "mpg")
  }

  cols <- feature_columns(
    column_numeric("disp"),
    column_numeric("cyl")
  )

  model <- linear_regressor(feature_columns = cols)

  indices <- sample(1:nrow(mtcars), size = 0.80 * nrow(mtcars))
  train <- mtcars[indices, ]
  test  <- mtcars[-indices, ]

  model %>% train(mtcars_input_fn(train))

  model
}

model <- mtcars_train()
```

The `export_savemodel()` will create the **pb** file and the **variables** folder

```{r}
# Create an input spec
input_spec <- regressor_parse_example_spec(feature_columns = feature_columns( 
                                             column_numeric("disp", "cyl")
                                           ),
                                           label_key = "input",
                                           label_dtype = tf$string)

# Parse the spec as an input receiver 
input_receiver <- tf$estimator$export$build_parsing_serving_input_receiver_fn(input_spec)

export_savedmodel(model, 
                  export_dir_base = "trained/tfestimators-mtcars",
                  serving_input_receiver_fn = input_receiver)

model_folder <- list.files()[1]

dir(model_path, recursive = TRUE)
```

## Exporting from Keras

First train a `keras` model as described under [R interface to Keras](https://tensorflow.rstudio.com/keras/), for convinience, run instead:

> Notice `set_learning_phase(TRUE)` to prevent 'You must feed a value for
> placeholder tensor 'dropout_1/keras_learning_phase' while serving set learning
> phase (see [stackoverflow.com/q/42025660](https://stackoverflow.com/questions/42025660/keras-set-learning-phase-for-dropout-when-saving-tensorflow-session),
> [keras/issues/2310](https://github.com/fchollet/keras/issues/2310), 
> [keras/issues/7720](https://github.com/fchollet/keras/issues/7720),
> [/tensorflow/serving/issues/310](https://github.com/tensorflow/serving/issues/310)).

```{r}
library(keras)
tf$reset_default_graph()

backend()$set_learning_phase(TRUE)

model <- mnist_train_keras(epochs = 1)
```

Then save using `export_savedmodel()` as follows:

```{r}
export_savedmodel(model, "trained/keras-mnist/1")

dir(model_path, recursive = TRUE)
```
